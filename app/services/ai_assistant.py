from __future__ import annotations
import os, re, json, difflib, unicodedata
from dataclasses import dataclass
from typing import Optional, Dict, Any, Tuple
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

from loguru import logger

# ======= –í–Ω–µ—à–Ω–∏–µ —Å–µ—Ä–≤–∏—Å—ã (–µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –Ω–∏—Ö) =======
try:
    from app.services.ai_client import mission_from_text  # –ò–ò: title/description/assignee_hint/deadline_text/priority
except Exception:
    mission_from_text = None

try:
    from app.services.nlp_deadlines import parse_deadline as nlp_parse
except Exception:
    nlp_parse = None

# ========= ENV / TZ =========
_TZ = os.getenv("TZ", os.getenv("TIMEZONE", "Europe/Kyiv"))
_ZONE = ZoneInfo(_TZ)
_START = int(os.getenv("WORKDAY_START_HOUR", "9"))
_END   = int(os.getenv("WORKDAY_END_HOUR", "20"))

__all__ = [
    "assistant_summarize_quick",
    "classify",
    "is_household_task",
    "render_street_mission",
    "difficulty_human_label",
]

ASSIGNEE_RE = re.compile(r"@([A-Za-z0-9_]{3,32})")
_TIME_RE = re.compile(r"(?<!\d)([01]?\d|2[0-3])[:\.]\s?([0-5]\d)(?!\d)")

def _has_explicit_time(s: Optional[str]) -> bool:
    if not s:
        return False
    return bool(_TIME_RE.search(s))

# ====== –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ======
def _norm(s: Optional[str]) -> str:
    return (s or "").strip()

def _normalize_text(s: str) -> str:
    s = s.lower().strip()
    s = unicodedata.normalize("NFKD", s)
    s = s.replace("—ë", "–µ").replace("–π", "–∏")
    return s

def _tokenize(s: str) -> list[str]:
    s = _normalize_text(s)
    return re.findall(r"[a-z–∞-—è0-9]+", s)

# ====== –ö–∞—Ç–µ–≥–æ—Ä–∏–∏/–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ ======
HOUSEHOLD = (
    "–≤—ã–Ω–µ—Å–∏ –º—É—Å–æ—Ä", "–≤—ã–Ω–µ—Å—Ç–∏ –º—É—Å–æ—Ä", "–º—É—Å–æ—Ä", "—É–±–æ—Ä", "—É–±—Ä–∞—Ç—å", "—É–±–æ—Ä–∫–∞",
    "–ø–æ–º—ã—Ç—å", "–ø–æ–º—ã—Ç—å –ø–æ–ª", "–ø–æ–º—ã—Ç—å –ø–æ–ª—ã", "–º—ã—Ç—å–µ –ø–æ–ª–æ–≤", "–º—ã—Ç—å—ë –ø–æ–ª–æ–≤",
    "–ø–æ–¥–º–µ—Å—Ç–∏", "–ø—Ä–æ–ø—ã–ª–µ—Å–æ—Å–∏—Ç—å", "–ø–æ—Å—É–¥—É", "–ø–æ–º—ã—Ç—å –ø–æ—Å—É–¥—É",
    "—É–Ω–∏—Ç–∞–∑", "—Ä–∞–∫–æ–≤–∏–Ω—É", "–≤–∞–Ω–Ω—É", "–æ–∫–Ω–∞", "–ø–æ–º—ã—Ç—å –æ–∫–Ω–∞",
    "–∫—É–ø–∏—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã", "–∑–∞–∫—É–ø–∏—Ç—å—Å—è", "–º–∞–≥–∞–∑–∏–Ω",
    "–ø–æ–ª–∏—Ç—å —Ü–≤–µ—Ç—ã", "–ø–æ–ª–µ–π —Ü–≤–µ—Ç—ã", "—Ü–≤–µ—Ç—ã",
    "–ø–æ–∫–æ—Ä–º–∏—Ç—å", "–∫–æ—Ä–º", "–∂–∏–≤–æ—Ç–Ω–æ–µ", "—Å–æ–±–∞–∫—É", "–∫–æ—à–∫—É", "–∞–≥–∞–º—É", "—Ä—ã–±–æ–∫",
)

COVER = ("–æ–±–ª–æ–∂–∫", "cover", "–∞—Ä—Ç", "artwork", "–æ–±–ª–æ–∂–∫–∞ –∫ —Ç—Ä–µ–∫—É", "–¥–∏–∑–∞–π–Ω –æ–±–ª–æ–∂–∫–∏")

RECORD = (
    "–∑–∞–ø–∏—Å–∞—Ç—å —Ç—Ä–µ–∫", "–∑–∞–ø–∏—Å–∞—Ç—å –≤–æ–∫–∞–ª", "–∑–∞–ø–∏—Å–∞—Ç—å –∫—É–ø–ª–µ—Ç",
    "–∑–∞–ø–∏—Å—å —Ç—Ä–µ–∫–∞", "record", "–≤–æ–∫–∞–ª –∑–∞–ø–∏—Å–∞—Ç—å"
)

MIX = (
    "—Å–≤–µ—Å—Ç–∏ —Ç—Ä–µ–∫", "—Å–≤–µ—Å—Ç–∏ —Ç—Ä—ç–∫", "—Å–≤–µ–¥–µ–Ω–∏–µ", "—Å–≤–µ–¥–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞",
    "–º–∏–∫—Å", "–º–∏–∫—Å–¥–∞—É–Ω", "mix", "mixdown",
    "–º–∞—Å—Ç–µ—Ä", "–º–∞—Å—Ç–µ—Ä–∏–Ω–≥", "master", "mastering",
)

BEAT = ("—Å–¥–µ–ª–∞—Ç—å –±–∏—Ç", "–±–∏—Ç —Å–¥–µ–ª–∞—Ç—å", "–±–∏—Ç–æ–∫", "beat", "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª")

FULL_TRACK = ("–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–¥–µ–ª–∞—Ç—å —Ç—Ä–µ–∫", "–±–∏—Ç + –∑–∞–ø–∏—Å—å + —Å–≤–µ–¥–µ–Ω–∏–µ", "—Å –Ω—É–ª—è —Ç—Ä–µ–∫", "—Ñ—É–ª–ª —Ç—Ä–µ–∫", "full track")

PUBLISH = (
    "–æ–ø—É–±–ª–∏–∫–æ–≤", "–≤—ã–ª–æ–∂", "–∑–∞–ª–µ–π", "–∑–∞–≥—Ä—É–∑", "–Ω–∞ –ø–ª–æ—â–∞–¥–∫", "–Ω–∞ dsp",
    "spotify", "apple music", "yandex music", "boom", "vk music",
)

SNIPPET = ("—Å–Ω–∏–ø–ø–µ—Ç", "—Å–Ω–∏–ø", "—Ç–∏–∑–µ—Ä", "shorts", "—à–æ—Ä—Ç—Å", "reels", "—Ä–∏–ª—Å", "—à–æ—Ä—Ç")

# –í–∏–¥–µ–æ–ø—Ä–æ–¥–∞–∫—à–Ω / –∫–ª–∏–ø—ã / —Å—Ç—É–¥–∏—è
SHOOT_LOCATION = ("–æ—Ç—Å–Ω—è—Ç—å –ª–æ–∫–∞—Ü–∏—é", "—Å–Ω—è—Ç—å –ª–æ–∫–∞—Ü–∏—é", "–ª–æ–∫–∞—Ü–∏—è", "–≤—ã–µ–∑–¥ –Ω–∞ –ª–æ–∫–∞—Ü–∏—é", "–ª–æ–∫–∞—Ü–∏–∏")
APPEAR_LOCATION = ("—Å–Ω—è—Ç—å—Å—è", "—Å–Ω–∏–º–∏—Å—å", "–±—ã—Ç—å –≤ –∫–∞–¥—Ä–µ", "—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å—ä–µ–º–∫–µ", "—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å—ä—ë–º–∫–µ")
FILMING = ("—Å–Ω–∏–º–∞—Ç—å", "—Å—ä–µ–º–∫–∞", "—Å—ä—ë–º–∫–∞", "—Å–Ω—è—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª", "–Ω–∞—Å–Ω–∏–º–∞–π", "–Ω–∞–æ—Ç—Å–Ω–∏–º–∞–π", "–æ–ø–µ—Ä–∞—Ç–æ—Ä")
EDITING = ("—Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å", "–º–æ–Ω—Ç–∞–∂", "–ø–æ—Ä–µ–∑–∞—Ç—å", "–Ω–∞—Ä–µ–∑–∫–∞", "—Å–∫–ª–µ–π–∫–∞", "–≤–∏–¥–µ–æ –º–æ–Ω—Ç–∞–∂", "videomontage")
COLOR = ("—Ü–≤–µ—Ç–æ–∫–æ—Ä", "color", "color grading", "grading", "–ø–æ–∫—Ä–∞—Å", "–∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ü–≤–µ—Ç–∞")
SCRIPT = ("—Å—Ü–µ–Ω–∞—Ä–∏–π", "—Ç–µ—Ö–∑–∞–¥–∞–Ω–∏–µ", "—Ç–∑", "—Ä–∞—Å–∫–∞–¥—Ä–æ–≤–∫–∞", "—Å—Ç–æ—Ä–∏–±–æ—Ä–¥", "treatment", "–∏–¥–µ—è")
GEAR = ("–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ", "–æ—Å–≤–µ—Ç", "—Å–≤–µ—Ç", "–º–∏–∫—Ä–æ—Ñ–æ–Ω", "—Ä–µ–∫–æ—Ä–¥–µ—Ä", "—à—Ç–∞—Ç–∏–≤", "—Å—Ç–µ–¥–∏–∫–∞–º", "–≥–∏–º–±–∞–ª", "–∞—Ä–µ–Ω–¥–∞ —Ç–µ—Ö–Ω–∏–∫–∏", "–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Å—Ç—É–¥–∏—é")

_NUM_WORDS = {"–¥–≤–∞":2,"–¥–≤–µ":2,"—Ç—Ä–∏":3,"—á–µ—Ç—ã—Ä–µ":4,"–ø—è—Ç—å":5,"—à–µ—Å—Ç—å":6,"—Å–µ–º—å":7,"–≤–æ—Å–µ–º—å":8,"–¥–µ–≤—è—Ç—å":9,"–¥–µ—Å—è—Ç—å":10}
_SNIPPET_COUNT_RE = re.compile(r"(?<!\d)(\d{1,2})\s*(—Å–Ω–∏–ø–ø–µ—Ç\w*|—Å–Ω–∏–ø\w*|—Ç–∏–∑–µ—Ä\w*|—à–æ—Ä—Ç—Å?\w*|shorts?|reels?)")
_SNIPPET_WORDCOUNT_RE = re.compile(r"\b(" + "|".join(_NUM_WORDS.keys()) + r")\b\s*(—Å–Ω–∏–ø–ø–µ—Ç\w*|—Å–Ω–∏–ø\w*|—Ç–∏–∑–µ—Ä\w*|—à–æ—Ä—Ç—Å?\w*|shorts?|reels?)")

# ====== –§–∞–∑–∑–∏-–º–∞—Ç—á–∏–Ω–≥ ======
def _fuzzy_contains(text: str, variants: tuple[str, ...], *, threshold: float = 0.78) -> bool:
    toks = _tokenize(text)
    if not toks:
        return False
    windows = []
    for n in (1, 2, 3, 4):
        for i in range(0, len(toks) - n + 1):
            windows.append(" ".join(toks[i:i+n]))
    for v in variants:
        v_norm = " ".join(_tokenize(v))
        if not v_norm:
            continue
        joined = " ".join(toks)
        if v_norm in joined:
            return True
        for w in windows:
            if difflib.SequenceMatcher(None, w, v_norm).ratio() >= threshold:
                return True
    return False

def _contains_any(text: str, patterns: tuple[str, ...]) -> bool:
    t = _normalize_text(text)
    return any(p in t for p in patterns)

def _count_snippets(text: str) -> int:
    t = _normalize_text(text)
    n = 0
    for m in _SNIPPET_COUNT_RE.finditer(t):
        try:
            n = max(n, int(m.group(1)))
        except Exception:
            pass
    for m in _SNIPPET_WORDCOUNT_RE.finditer(t):
        n = max(n, _NUM_WORDS.get(m.group(1), 0))
    if n == 0 and any(k in t for k in SNIPPET):
        occ = sum(t.count(k) for k in set(SNIPPET))
        n = max(1, min(occ, 5))
    return n

# ====== –°–ª–æ–∂–Ω–æ—Å—Ç—å ======
def _difficulty_from_text(text: str) -> int:
    """
    –ß–µ—Å—Ç–Ω–∞—è —à–∫–∞–ª–∞ 1..5 —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –∏ —Ñ–∞–∑–∑–∏:
      5 ‚Äî ¬´–ø–æ–ª–Ω—ã–π —Ç—Ä–µ–∫¬ª
      4 ‚Äî —Å–≤–µ–¥–µ–Ω–∏–µ/–º–∞—Å—Ç–µ—Ä–∏–Ω–≥, –∑–∞–ø–∏—Å—å
      3 ‚Äî –æ—Ç—Å–Ω—è—Ç—å –ª–æ–∫–∞—Ü–∏—é, —Å—ä—ë–º–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞, –º–æ–Ω—Ç–∞–∂ (–Ω–µ —Å–Ω–∏–ø–ø–µ—Ç), —Ü–≤–µ—Ç–æ–∫–æ—Ä, —Å—Ü–µ–Ω–∞—Ä–∏–π/—Ä–∞—Å–∫–∞–¥—Ä–æ–≤–∫–∞, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞/—Å–≤–µ—Ç/–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
      2 ‚Äî –æ–±–ª–æ–∂–∫–∞, —Å–Ω—è—Ç—å—Å—è –≤ –∫–∞–¥—Ä–µ, —Å–¥–µ–ª–∞—Ç—å –±–∏—Ç
      1 ‚Äî –ø—É–±–ª–∏–∫–∞—Ü–∏—è, –±—ã—Ç–æ–≤—É—Ö–∞, *N —Å–Ω–∏–ø–ø–µ—Ç–æ–≤ = N* (–¥–æ 5)
    """
    t = _normalize_text(text)

    if _fuzzy_contains(t, FULL_TRACK):
        return 5

    sn = _count_snippets(t)
    if sn > 0:
        return max(1, min(5, sn))

    if _fuzzy_contains(t, SHOOT_LOCATION) and "—Å–Ω—è—Ç—Å" not in t:
        return 3
    if _fuzzy_contains(t, APPEAR_LOCATION) and "–ª–æ–∫–∞—Ü" in t:
        return 2
    if _fuzzy_contains(t, FILMING) and "—Å–Ω—è—Ç—Å" not in t:
        return 3
    if _fuzzy_contains(t, EDITING):
        return 3
    if _fuzzy_contains(t, COLOR):
        return 3
    if _fuzzy_contains(t, SCRIPT):
        return 3
    if _fuzzy_contains(t, GEAR):
        return 3 if len(t) > 60 else 2

    if _fuzzy_contains(t, MIX):
        return 4
    if _fuzzy_contains(t, RECORD):
        return 4
    if _fuzzy_contains(t, COVER):
        return 2
    if _fuzzy_contains(t, PUBLISH):
        return 1
    if _fuzzy_contains(t, HOUSEHOLD):
        return 1
    if _fuzzy_contains(t, BEAT):
        return 2

    base = 1
    if any(k in t for k in ("–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏", "–∞–Ω–∞–ª–∏—Ç", "—Å–∫—Ä–∏–ø—Ç", "–±–æ—Ç", "—Å—Ü–µ–Ω–∞—Ä–∏", "—Å—ä–µ–º–∫", "—Å—ä—ë–º–∫", "–º–æ–Ω—Ç–∞–∂", "—Ü–≤–µ—Ç–æ–∫–æ—Ä")):
        base += 1
    if len(t) > 140:
        base += 1
    return max(1, min(5, base))

def _difficulty_label(points: int) -> str:
    labels = {
        1: "üü¢ –õ—ë–≥–∫–∞—è",
        2: "üü° –°—Ä–µ–¥–Ω—è—è",
        3: "üü† –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–π",
        4: "üî¥ –¢—è–∂—ë–ª–∞—è",
        5: "üü£ –•–∞—Ä–¥–∫–æ—Ä",
    }
    return labels.get(max(1, min(5, int(points or 1))), "üü° –°—Ä–µ–¥–Ω—è—è")

def difficulty_human_label(points: int) -> str:
    return _difficulty_label(points)

# ====== –°–ª–æ—Ç –≤—Ä–µ–º–µ–Ω–∏ (—É—Ç—Ä–æ/–≤–µ—á–µ—Ä/–¥–µ–Ω—å/–Ω–æ—á—å) ======
def _fix_slot_time(dt: datetime, slot_hint: Optional[str]) -> datetime:
    if not slot_hint:
        return dt
    s = slot_hint.lower()
    if "—É—Ç—Ä" in s:
        hh = max(_START, 8)
        if hh < 8 or hh > 11: hh = 10
        return dt.replace(hour=hh, minute=0, second=0, microsecond=0, tzinfo=_ZONE)
    if "–≤–µ—á–µ—Ä" in s:
        hh = min(_END, 21)
        if hh < 18 or hh > 21: hh = 19
        return dt.replace(hour=hh, minute=0, second=0, microsecond=0, tzinfo=_ZONE)
    if "–æ–±–µ–¥" in s or "–¥–Ω" in s:
        hh = max(_START + 3, 12)
        if hh > 15: hh = 13
        return dt.replace(hour=hh, minute=0, second=0, microsecond=0, tzinfo=_ZONE)
    if "–Ω–æ—á" in s:
        return dt.replace(hour=22, minute=0, second=0, microsecond=0, tzinfo=_ZONE)
    return dt

# ====== –§–æ–ª–ª–±–µ–∫-–ø–∞—Ä—Å–µ—Ä –¥–µ–¥–ª–∞–π–Ω–æ–≤ (RU) ======
_DMY_RE = re.compile(r"(?<!\d)(\d{1,2})[.\-\/](\d{1,2})(?:[.\-\/](\d{2,4}))?(?!\d)")
WEEKDAYS = {
    "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫":0, "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫—É":0, "–≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫":0, "–∫ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫—É":0,
    "–≤—Ç–æ—Ä–Ω–∏–∫":1, "–≤—Ç–æ—Ä–Ω–∏–∫—É":1, "–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫":1, "–∫ –≤—Ç–æ—Ä–Ω–∏–∫—É":1,
    "—Å—Ä–µ–¥–∞":2, "—Å—Ä–µ–¥—É":2, "–∫ —Å—Ä–µ–¥–µ":2, "–≤ —Å—Ä–µ–¥—É":2,
    "—á–µ—Ç–≤–µ—Ä–≥":3, "–∫ —á–µ—Ç–≤–µ—Ä–≥—É":3, "–≤ —á–µ—Ç–≤–µ—Ä–≥":3,
    "–ø—è—Ç–Ω–∏—Ü–∞":4, "–ø—è—Ç–Ω–∏—Ü—É":4, "–∫ –ø—è—Ç–Ω–∏—Ü–µ":4, "–≤ –ø—è—Ç–Ω–∏—Ü—É":4,
    "—Å—É–±–±–æ—Ç–∞":5, "—Å—É–±–±–æ—Ç—É":5, "–∫ —Å—É–±–±–æ—Ç–µ":5, "–≤ —Å—É–±–±–æ—Ç—É":5,
    "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ":6, "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—é":6, "–∫ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—é":6, "–≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ":6,
}

def _next_weekday(base: datetime, target_wd: int) -> datetime:
    days_ahead = (target_wd - base.weekday()) % 7
    if days_ahead == 0:
        days_ahead = 7
    return base + timedelta(days=days_ahead)

def _ru_deadline_parse(text: str, now: Optional[datetime] = None) -> Optional[datetime]:
    if not text:
        return None
    t = text.lower()
    now = now or datetime.now(_ZONE)

    tm = _TIME_RE.search(t)
    hh, mm = (None, None)
    if tm:
        hh = int(tm.group(1))
        mm = int(tm.group(2))

    slot = None
    if any(w in t for w in ("—É—Ç—Ä", "—É—Ç—Ä–æ–º")): slot = "—É—Ç—Ä–æ"
    elif any(w in t for w in ("–≤–µ—á–µ—Ä", "–≤–µ—á–µ—Ä–æ–º")): slot = "–≤–µ—á–µ—Ä"
    elif any(w in t for w in ("–æ–±–µ–¥", "–¥–Ω—ë–º", "–¥–Ω–µ–º")): slot = "–¥–µ–Ω—å"
    elif any(w in t for w in ("–Ω–æ—á", "–Ω–æ—á—å—é")): slot = "–Ω–æ—á—å"

    if "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞" in t:
        base = now + timedelta(days=2)
    elif "–∑–∞–≤—Ç—Ä–∞" in t:
        base = now + timedelta(days=1)
    elif "—Å–µ–≥–æ–¥–Ω—è" in t:
        base = now
    else:
        base = None

    if base is None:
        m = _DMY_RE.search(t)
        if m:
            d, mth, yr = int(m.group(1)), int(m.group(2)), m.group(3)
            if yr:
                yr = int(yr)
                if yr < 100:
                    yr += 2000
            else:
                yr = now.year
                try:
                    probe = datetime(yr, mth, d, tzinfo=_ZONE)
                    if probe.date() < now.date():
                        yr += 1
                except Exception:
                    pass
            try:
                base = datetime(yr, mth, d, tzinfo=_ZONE)
            except Exception:
                base = None

    if base is None:
        for key, wd in WEEKDAYS.items():
            if key in t:
                base = _next_weekday(now, wd)
                break

    if base is None:
        return None

    if hh is not None and mm is not None:
        dt = base.replace(hour=hh, minute=mm, second=0, microsecond=0)
    else:
        if slot == "—É—Ç—Ä–æ":
            hh_final = max(_START, 9)
            dt = base.replace(hour=hh_final, minute=0, second=0, microsecond=0)
        elif slot == "–≤–µ—á–µ—Ä":
            hh_final = min(_END, 20)
            dt = base.replace(hour=hh_final, minute=0, second=0, microsecond=0)
        elif slot == "–¥–µ–Ω—å":
            dt = base.replace(hour=13, minute=0, second=0, microsecond=0)
        elif slot == "–Ω–æ—á—å":
            dt = base.replace(hour=22, minute=0, second=0, microsecond=0)
        else:
            mid = (_START + _END) // 2
            dt = base.replace(hour=mid, minute=0, second=0, microsecond=0)
    return dt

# ====== –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–¥–ª–∞–π–Ω–∞ ======
def _format_deadline(dt) -> Tuple[Optional[int], Optional[str]]:
    if dt is None:
        return None, None
    if isinstance(dt, (int, float)):
        dt_local = datetime.fromtimestamp(int(dt), tz=_ZONE)
    elif isinstance(dt, datetime):
        dt_local = dt.astimezone(_ZONE)
    else:
        return None, None
    ts = int(dt_local.timestamp())
    s = dt_local.strftime("%Y-%m-%d %H:%M")
    return ts, s

def _choose_greeting() -> str:
    return ["–°–ª—ã—à—å", "–ô–æ", "–ù—É —á—ë", "–ê–ª–æ", "–ë—Ä–∞—Ç–µ–ª–ª–æ"][hash(os.times()) % 5]

def _safe_username(s: Optional[str]) -> Optional[str]:
    if not s:
        return None
    s = s.strip()
    return "@" + s.lstrip("@")

# ====== –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ======
async def assistant_summarize_quick(raw_text: str) -> Dict[str, Any]:
    text = _norm(raw_text)
    if not text:
        return {
            "is_valid": False,
            "violation": "–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç",
            "title": "–ú–∏—Å—Å–∏—è",
            "description_og": "",
            "difficulty_points": 1,
            "difficulty_label": _difficulty_label(1),
            "deadline_ts": None,
            "assignee_username": None,
        }

    # 1) –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –∏–∑ —Ç–µ–∫—Å—Ç–∞
    assignee_from_text = None
    m = ASSIGNEE_RE.search(text)
    if m:
        assignee_from_text = "@" + m.group(1)

    # 2) –ò–ò-–ø–æ–¥—Å–∫–∞–∑–∫–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
    ai_title = "–ú–∏—Å—Å–∏—è"
    ai_desc = text
    deadline_hint = None
    assignee_hint = assignee_from_text
    if callable(mission_from_text):
        try:
            ai = await mission_from_text(text)
            if ai:
                ai_title = _norm(ai.get("title")) or ai_title
                ai_desc = text
                deadline_hint = _norm(ai.get("deadline_text"))
                assignee_hint = _safe_username(ai.get("assignee_hint")) or assignee_hint
        except Exception as e:
            logger.warning(f"[assistant] mission_from_text failed: {e}")

    # 3) –î–µ–¥–ª–∞–π–Ω: –≤–Ω–µ—à–Ω–∏–π –ø–∞—Ä—Å–µ—Ä ‚Üí —Ñ–æ–ª–ª–±–µ–∫ ‚Üí —Å–ª–æ—Ç—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    due_dt: Optional[datetime] = None
    src = deadline_hint or text
    try:
        if callable(nlp_parse):
            due = nlp_parse(src)
            if isinstance(due, (int, float)):
                due_dt = datetime.fromtimestamp(int(due), tz=_ZONE)
            elif isinstance(due, datetime):
                due_dt = due
    except Exception as e:
        logger.warning(f"[assistant] nlp_parse failed: {e}")

    if not isinstance(due_dt, datetime):
        try:
            due_dt = _ru_deadline_parse(src)
        except Exception as e:
            logger.warning(f"[assistant] fallback parse failed: {e}")
            due_dt = None

    if isinstance(due_dt, datetime):
        if not _has_explicit_time(src):
            due_dt = _fix_slot_time(due_dt, src)

    deadline_ts, deadline_str = _format_deadline(due_dt)

    # 4) –°–ª–æ–∂–Ω–æ—Å—Ç—å/–∫–∞—Ä–º–∞
    difficulty = _difficulty_from_text(text)
    label = _difficulty_label(difficulty)
    karma_points = difficulty

    # 5) –ò—Ç–æ–≥
    return {
        "is_valid": True,
        "violation": "",
        "title": ai_title,
        "description_og": ai_desc,
        "difficulty_points": difficulty,
        "difficulty_label": label,
        "deadline_ts": deadline_ts,
        "deadline_str": deadline_str,
        "assignee_username": assignee_hint,
        "karma_points": karma_points,
    }

# ====== –†–µ–Ω–¥–µ—Ä ¬´—É–ª–∏—á–Ω–æ–≥–æ¬ª —Å–æ–æ–±—â–µ–Ω–∏—è ======
def render_street_mission(
    analysis: Dict[str, Any],
    requester_name: Optional[str] = None,
    assignee_name: Optional[str] = None,
) -> str:
    greet = _choose_greeting()
    who = (assignee_name or analysis.get("assignee_username") or "–±—Ä–æ–¥—è–≥–∞")
    title = _norm(analysis.get("title")) or "–ú–∏—Å—Å–∏—è"
    original = _norm(analysis.get("description_og"))
    diff = int(analysis.get("difficulty_points") or 1)
    label = _difficulty_label(diff)
    karma_points = int(analysis.get("karma_points") or diff)

    deadline_str = analysis.get("deadline_str") or ""
    if not deadline_str and analysis.get("deadline_ts"):
        dt = datetime.fromtimestamp(int(analysis["deadline_ts"]), tz=_ZONE)
        deadline_str = dt.strftime("%Y-%m-%d %H:%M")

    rq = _norm(requester_name) or "–ó–∞–∫–∞–∑—á–∏–∫"
    asg = _norm(assignee_name or analysis.get("assignee_username")) or "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å"

    lines = [
        f"{greet}, {who}!",
        f"–ó–∞–¥–∞—á–∞: {title}",
        f"–¢–µ–∫—Å—Ç: {original}",
    ]
    if deadline_str:
        lines.append(f"–î–µ–¥–ª–∞–π–Ω: {deadline_str}")
    lines.extend([
        f"–°–ª–æ–∂–Ω–æ—Å—Ç—å: {label} ({diff}/5)",
        f"–ö–∞—Ä–º–∞: +{karma_points}",
        f"–ó–∞–∫–∞–∑—á–∏–∫: {rq}",
        f"–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {asg}",
        "–î–∞–≤–∞–π –ø–æ-OG ‚Äî –±–µ–∑ —Å—É–µ—Ç—ã, –Ω–æ —á–µ—Ç–∫–æ. üí™",
    ])
    return "\n".join(lines)

# ====== –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å ======
async def classify(text: str) -> Dict[str, Any]:
    return await assistant_summarize_quick(text)

def is_household_task(text: str) -> bool:
    t = _normalize_text(text or "")
    return any(k in t for k in HOUSEHOLD)
